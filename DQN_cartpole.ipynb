{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsAptYSXVxEU",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650.0
    },
    "outputId": "495ff42f-5fea-4219-8c33-cb30d057412e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-1-ef5dfd9b7a46>:112: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-1-ef5dfd9b7a46>:120: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-1-ef5dfd9b7a46>:121: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-1-ef5dfd9b7a46>:123: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "\n",
    "#### Logging\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "root_logdir = 'tf_logs'\n",
    "logdir = '{}/run-{}/'.format(root_logdir, now)\n",
    "###### Agent\n",
    "class PolyGradAgent(object):\n",
    "    \n",
    "    def __init__(self, action_space):\n",
    "        \n",
    "        ### model hyperparameters\n",
    "\n",
    "        self.epsilon = 0.9  # how much do we explore initially\n",
    "        self.epsilon_decay_rate = 0.95  # rate by which exploration decreases, used for constant epsilon decay strategy\n",
    "        self.high_score = 0  # keep track of highest score obtained thus far\n",
    "        self.did_well_threshold = 0.80  # how close we need to be to our high score to have \"done well\"\n",
    "        self.network_has_had_training = False  # has our neural net had any training\n",
    "        self.last_good_batch = tuple()  # memory for the last good episode we eperienced \n",
    "        \n",
    "        self.experience = 0  # integer for keeping track of how much good experience we've had, used in custom epsilon decay function\n",
    "            \n",
    "        self.last_10_episode_scores = deque(maxlen = 10) # last 10 episode average reward\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "       Function for letting us know if we did well based on the rewards received this episode and the \n",
    "       did_well_threshold parameter.\n",
    "    \"\"\"\n",
    "    def did_we_do_well(self, episode_rewards):\n",
    "\n",
    "        if episode_rewards > self.did_well_threshold * self.high_score:\n",
    "\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "       Function for adding an experience memory from episodes were we've \"done well\".\n",
    "    \"\"\"\n",
    "    def add_to_experience(self, episode_length):\n",
    "\n",
    "        self.experience += episode_length\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        Function that updates our highest score acheived thus far.\n",
    "    \"\"\"\n",
    "    def update_high_score(self, episode_rewards):\n",
    "\n",
    "        if episode_rewards > self.high_score:\n",
    "\n",
    "            self.high_score = episode_rewards\n",
    "\n",
    " \n",
    "\n",
    "    \"\"\"\n",
    "        Typical epsilon decay function.\n",
    "    \"\"\"\n",
    "    def decay_epsilon(self):\n",
    "\n",
    "        self.epsilon *= self.epsilon_decay_rate\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        Customized epsilon decay function.\n",
    "    \"\"\"\n",
    "    def decay_epsilon_custom(self):\n",
    "            \n",
    "    ## decaying epsilon strategy for fast solution convergence, average solution ~450 episodes\n",
    "       \n",
    "        if self.experience > 0:\n",
    "            self.epsilon = 0.9\n",
    "        if self.experience > 500:\n",
    "            self.epsilon = 0.7\n",
    "        if self.experience > 1000:\n",
    "            self.epsilon = 0.6\n",
    "        if self.experience > 2000:\n",
    "            self.epsilon = 0.5\n",
    "        if self.experience > 3000:\n",
    "            self.epsilon = 0.5\n",
    "        if self.experience > 4000:\n",
    "            self.epsilon = 0.4\n",
    "        if self.experience > 5000:\n",
    "            self.epsilon = 0.3\n",
    "        if self.experience > 6000:\n",
    "            self.epsilon = 0.2\n",
    "        if self.experience > 7000:\n",
    "            self.epsilon = 0.1\n",
    "\n",
    "### Set up lstm\n",
    "\n",
    "sess = tf.InteractiveSession()  # Initialize an interactive session\n",
    "\n",
    "n_steps = 1\n",
    "n_inputs = 4\n",
    "n_neurons = 30\n",
    "n_outputs = 2\n",
    "n_layers = 3\n",
    "\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\n",
    "learning_rate = 0.001\n",
    "\n",
    "state = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "actions = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "lstm_cells = [tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\n",
    "              for layer in range(n_layers)]\n",
    "multi_cell = tf.contrib.rnn.MultiRNNCell(lstm_cells)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell, state, dtype=tf.float32)\n",
    "top_layer_h_state = states[-1][1]\n",
    "logits = tf.layers.dense(top_layer_h_state, n_outputs, name=\"softmax\")\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=actions, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_step = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, actions, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "## Logging\n",
    "loss_summary = tf.summary.scalar('Loss', loss)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5okapkbV8lB",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000.0
    },
    "outputId": "b38259de-a88b-4d04-bf2a-6dc59035994c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Rewards: 10.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "0\n",
      "Running average of last 10 episodes: 10.0\n",
      "Episode: 1, Rewards: 12.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "10\n",
      "Running average of last 10 episodes: 11.0\n",
      "Episode: 2, Rewards: 25.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "22\n",
      "Running average of last 10 episodes: 15.666666666666666\n",
      "Episode: 3, Rewards: 18.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "47\n",
      "Running average of last 10 episodes: 16.25\n",
      "Episode: 4, Rewards: 18.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "47\n",
      "Running average of last 10 episodes: 16.6\n",
      "Episode: 5, Rewards: 15.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "47\n",
      "Running average of last 10 episodes: 16.333333333333332\n",
      "Episode: 6, Rewards: 11.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "47\n",
      "Running average of last 10 episodes: 15.571428571428571\n",
      "Episode: 7, Rewards: 14.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "47\n",
      "Running average of last 10 episodes: 15.375\n",
      "Episode: 8, Rewards: 16.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "47\n",
      "Running average of last 10 episodes: 15.444444444444445\n",
      "Episode: 9, Rewards: 14.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "47\n",
      "Running average of last 10 episodes: 15.3\n",
      "Episode: 10, Rewards: 18.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "47\n",
      "Running average of last 10 episodes: 16.1\n",
      "Episode: 11, Rewards: 28.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "47\n",
      "Running average of last 10 episodes: 17.7\n",
      "Episode: 12, Rewards: 13.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "75\n",
      "Running average of last 10 episodes: 16.5\n",
      "Episode: 13, Rewards: 11.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "75\n",
      "Running average of last 10 episodes: 15.8\n",
      "Episode: 14, Rewards: 20.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "75\n",
      "Running average of last 10 episodes: 16.0\n",
      "Episode: 15, Rewards: 12.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "75\n",
      "Running average of last 10 episodes: 15.7\n",
      "Episode: 16, Rewards: 18.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "75\n",
      "Running average of last 10 episodes: 16.4\n",
      "Episode: 17, Rewards: 9.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "75\n",
      "Running average of last 10 episodes: 15.9\n",
      "Episode: 18, Rewards: 38.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "75\n",
      "Running average of last 10 episodes: 18.1\n",
      "Episode: 19, Rewards: 28.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "113\n",
      "Running average of last 10 episodes: 19.5\n",
      "Episode: 20, Rewards: 14.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "113\n",
      "Running average of last 10 episodes: 19.1\n",
      "Episode: 21, Rewards: 15.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "113\n",
      "Running average of last 10 episodes: 17.8\n",
      "Episode: 22, Rewards: 28.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "113\n",
      "Running average of last 10 episodes: 19.3\n",
      "Episode: 23, Rewards: 28.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "113\n",
      "Running average of last 10 episodes: 21.0\n",
      "Episode: 24, Rewards: 16.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "113\n",
      "Running average of last 10 episodes: 20.6\n",
      "Episode: 25, Rewards: 14.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "113\n",
      "Running average of last 10 episodes: 20.8\n",
      "Episode: 26, Rewards: 22.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "113\n",
      "Running average of last 10 episodes: 21.2\n",
      "Episode: 27, Rewards: 17.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "113\n",
      "Running average of last 10 episodes: 22.0\n",
      "Episode: 28, Rewards: 22.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "113\n",
      "Running average of last 10 episodes: 20.4\n",
      "Episode: 29, Rewards: 36.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "113\n",
      "Running average of last 10 episodes: 21.2\n",
      "Episode: 30, Rewards: 12.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "149\n",
      "Running average of last 10 episodes: 21.0\n",
      "Episode: 31, Rewards: 19.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "149\n",
      "Running average of last 10 episodes: 21.4\n",
      "Episode: 32, Rewards: 18.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "149\n",
      "Running average of last 10 episodes: 20.4\n",
      "Episode: 33, Rewards: 21.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "149\n",
      "Running average of last 10 episodes: 19.7\n",
      "Episode: 34, Rewards: 11.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "149\n",
      "Running average of last 10 episodes: 19.2\n",
      "Episode: 35, Rewards: 14.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "149\n",
      "Running average of last 10 episodes: 19.2\n",
      "Episode: 36, Rewards: 30.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "149\n",
      "Running average of last 10 episodes: 20.0\n",
      "Episode: 37, Rewards: 10.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "149\n",
      "Running average of last 10 episodes: 19.3\n",
      "Episode: 38, Rewards: 37.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "149\n",
      "Running average of last 10 episodes: 20.8\n",
      "Episode: 39, Rewards: 24.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 19.6\n",
      "Episode: 40, Rewards: 13.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 19.7\n",
      "Episode: 41, Rewards: 18.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 19.6\n",
      "Episode: 42, Rewards: 16.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 19.4\n",
      "Episode: 43, Rewards: 22.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 19.5\n",
      "Episode: 44, Rewards: 12.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 19.6\n",
      "Episode: 45, Rewards: 20.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 20.2\n",
      "Episode: 46, Rewards: 19.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 19.1\n",
      "Episode: 47, Rewards: 21.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 20.2\n",
      "Episode: 48, Rewards: 19.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 18.4\n",
      "Episode: 49, Rewards: 26.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 18.6\n",
      "Episode: 50, Rewards: 12.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 18.5\n",
      "Episode: 51, Rewards: 15.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 18.2\n",
      "Episode: 52, Rewards: 9.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 17.5\n",
      "Episode: 53, Rewards: 16.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 16.9\n",
      "Episode: 54, Rewards: 19.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 17.6\n",
      "Episode: 55, Rewards: 26.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 18.2\n",
      "Episode: 56, Rewards: 33.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "186\n",
      "Running average of last 10 episodes: 19.6\n",
      "Episode: 57, Rewards: 15.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "219\n",
      "Running average of last 10 episodes: 19.0\n",
      "Episode: 58, Rewards: 18.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "219\n",
      "Running average of last 10 episodes: 18.9\n",
      "Episode: 59, Rewards: 26.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "219\n",
      "Running average of last 10 episodes: 18.9\n",
      "Episode: 60, Rewards: 19.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "219\n",
      "Running average of last 10 episodes: 19.6\n",
      "Episode: 61, Rewards: 10.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "219\n",
      "Running average of last 10 episodes: 19.1\n",
      "Episode: 62, Rewards: 25.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "219\n",
      "Running average of last 10 episodes: 20.7\n",
      "Episode: 63, Rewards: 22.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "219\n",
      "Running average of last 10 episodes: 21.3\n",
      "Episode: 64, Rewards: 16.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "219\n",
      "Running average of last 10 episodes: 21.0\n",
      "Episode: 65, Rewards: 49.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "219\n",
      "Running average of last 10 episodes: 23.3\n",
      "Episode: 66, Rewards: 13.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "268\n",
      "Running average of last 10 episodes: 21.3\n",
      "Episode: 67, Rewards: 33.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "268\n",
      "Running average of last 10 episodes: 23.1\n",
      "Episode: 68, Rewards: 22.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "268\n",
      "Running average of last 10 episodes: 23.5\n",
      "Episode: 69, Rewards: 46.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "268\n",
      "Running average of last 10 episodes: 25.5\n",
      "Episode: 70, Rewards: 20.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "314\n",
      "Running average of last 10 episodes: 25.6\n",
      "Episode: 71, Rewards: 12.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "314\n",
      "Running average of last 10 episodes: 25.8\n",
      "Episode: 72, Rewards: 26.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "314\n",
      "Running average of last 10 episodes: 25.9\n",
      "Episode: 73, Rewards: 16.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "314\n",
      "Running average of last 10 episodes: 25.3\n",
      "Episode: 74, Rewards: 20.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "314\n",
      "Running average of last 10 episodes: 25.7\n",
      "Episode: 75, Rewards: 32.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "314\n",
      "Running average of last 10 episodes: 24.0\n",
      "Episode: 76, Rewards: 16.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "314\n",
      "Running average of last 10 episodes: 24.3\n",
      "Episode: 77, Rewards: 16.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "314\n",
      "Running average of last 10 episodes: 22.6\n",
      "Episode: 78, Rewards: 28.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "314\n",
      "Running average of last 10 episodes: 23.2\n",
      "Episode: 79, Rewards: 15.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "314\n",
      "Running average of last 10 episodes: 20.1\n",
      "Episode: 80, Rewards: 9.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "314\n",
      "Running average of last 10 episodes: 19.0\n",
      "Episode: 81, Rewards: 19.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "314\n",
      "Running average of last 10 episodes: 19.7\n",
      "Episode: 82, Rewards: 15.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "314\n",
      "Running average of last 10 episodes: 18.6\n",
      "Episode: 83, Rewards: 42.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "314\n",
      "Running average of last 10 episodes: 21.2\n",
      "Episode: 84, Rewards: 16.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "356\n",
      "Running average of last 10 episodes: 20.8\n",
      "Episode: 85, Rewards: 35.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "356\n",
      "Running average of last 10 episodes: 21.1\n",
      "Episode: 86, Rewards: 22.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "356\n",
      "Running average of last 10 episodes: 21.7\n",
      "Episode: 87, Rewards: 10.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "356\n",
      "Running average of last 10 episodes: 21.1\n",
      "Episode: 88, Rewards: 11.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "356\n",
      "Running average of last 10 episodes: 19.4\n",
      "Episode: 89, Rewards: 14.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "356\n",
      "Running average of last 10 episodes: 19.3\n",
      "Episode: 90, Rewards: 12.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "356\n",
      "Running average of last 10 episodes: 19.6\n",
      "Episode: 91, Rewards: 43.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "356\n",
      "Running average of last 10 episodes: 22.0\n",
      "Episode: 92, Rewards: 53.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "399\n",
      "Running average of last 10 episodes: 25.8\n",
      "Episode: 93, Rewards: 17.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 23.3\n",
      "Episode: 94, Rewards: 18.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 23.5\n",
      "Episode: 95, Rewards: 10.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 21.0\n",
      "Episode: 96, Rewards: 17.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 20.5\n",
      "Episode: 97, Rewards: 17.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 21.2\n",
      "Episode: 98, Rewards: 16.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 21.7\n",
      "Episode: 99, Rewards: 22.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 22.5\n",
      "Episode: 100, Rewards: 12.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 22.5\n",
      "Episode: 101, Rewards: 19.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 20.1\n",
      "Episode: 102, Rewards: 34.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 18.2\n",
      "Episode: 103, Rewards: 14.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 17.9\n",
      "Episode: 104, Rewards: 19.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 18.0\n",
      "Episode: 105, Rewards: 9.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 17.9\n",
      "Episode: 106, Rewards: 27.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 18.9\n",
      "Episode: 107, Rewards: 37.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 20.9\n",
      "Episode: 108, Rewards: 28.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 22.1\n",
      "Episode: 109, Rewards: 44.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "452\n",
      "Running average of last 10 episodes: 24.3\n",
      "Episode: 110, Rewards: 69.0\n",
      "Epsilon: \n",
      "0.9\n",
      "Experince amount: \n",
      "496\n",
      "Running average of last 10 episodes: 30.0\n",
      "Episode: 111, Rewards: 35.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "565\n",
      "Running average of last 10 episodes: 31.6\n",
      "Episode: 112, Rewards: 31.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "565\n",
      "Running average of last 10 episodes: 31.3\n",
      "Episode: 113, Rewards: 38.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "565\n",
      "Running average of last 10 episodes: 33.7\n",
      "Episode: 114, Rewards: 36.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "565\n",
      "Running average of last 10 episodes: 35.4\n",
      "Episode: 115, Rewards: 67.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "565\n",
      "Running average of last 10 episodes: 41.2\n",
      "Episode: 116, Rewards: 75.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "632\n",
      "Running average of last 10 episodes: 46.0\n",
      "Episode: 117, Rewards: 94.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "707\n",
      "Running average of last 10 episodes: 51.7\n",
      "Episode: 118, Rewards: 42.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "801\n",
      "Running average of last 10 episodes: 53.1\n",
      "Episode: 119, Rewards: 80.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "801\n",
      "Running average of last 10 episodes: 56.7\n",
      "Episode: 120, Rewards: 33.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 53.1\n",
      "Episode: 121, Rewards: 10.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 50.6\n",
      "Episode: 122, Rewards: 25.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 50.0\n",
      "Episode: 123, Rewards: 37.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 49.9\n",
      "Episode: 124, Rewards: 61.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 52.4\n",
      "Episode: 125, Rewards: 42.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 49.9\n",
      "Episode: 126, Rewards: 59.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 48.3\n",
      "Episode: 127, Rewards: 17.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 40.6\n",
      "Episode: 128, Rewards: 34.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 39.8\n",
      "Episode: 129, Rewards: 21.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 33.9\n",
      "Episode: 130, Rewards: 75.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 38.1\n",
      "Episode: 131, Rewards: 16.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 38.7\n",
      "Episode: 132, Rewards: 69.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 43.1\n",
      "Episode: 133, Rewards: 58.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 45.2\n",
      "Episode: 134, Rewards: 47.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 43.8\n",
      "Episode: 135, Rewards: 47.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 44.3\n",
      "Episode: 136, Rewards: 19.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 40.3\n",
      "Episode: 137, Rewards: 32.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 41.8\n",
      "Episode: 138, Rewards: 23.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 40.7\n",
      "Episode: 139, Rewards: 24.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 41.0\n",
      "Episode: 140, Rewards: 91.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "881\n",
      "Running average of last 10 episodes: 42.6\n",
      "Episode: 141, Rewards: 37.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "972\n",
      "Running average of last 10 episodes: 44.7\n",
      "Episode: 142, Rewards: 113.0\n",
      "Epsilon: \n",
      "0.7\n",
      "Experince amount: \n",
      "972\n",
      "Running average of last 10 episodes: 49.1\n",
      "Episode: 143, Rewards: 30.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1085\n",
      "Running average of last 10 episodes: 46.3\n",
      "Episode: 144, Rewards: 100.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1085\n",
      "Running average of last 10 episodes: 51.6\n",
      "Episode: 145, Rewards: 48.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1185\n",
      "Running average of last 10 episodes: 51.7\n",
      "Episode: 146, Rewards: 67.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1185\n",
      "Running average of last 10 episodes: 56.5\n",
      "Episode: 147, Rewards: 56.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1185\n",
      "Running average of last 10 episodes: 58.9\n",
      "Episode: 148, Rewards: 33.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1185\n",
      "Running average of last 10 episodes: 59.9\n",
      "Episode: 149, Rewards: 60.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1185\n",
      "Running average of last 10 episodes: 63.5\n",
      "Episode: 150, Rewards: 56.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1185\n",
      "Running average of last 10 episodes: 60.0\n",
      "Episode: 151, Rewards: 48.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1185\n",
      "Running average of last 10 episodes: 61.1\n",
      "Episode: 152, Rewards: 60.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1185\n",
      "Running average of last 10 episodes: 55.8\n",
      "Episode: 153, Rewards: 57.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1185\n",
      "Running average of last 10 episodes: 58.5\n",
      "Episode: 154, Rewards: 80.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1185\n",
      "Running average of last 10 episodes: 56.5\n",
      "Episode: 155, Rewards: 99.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1185\n",
      "Running average of last 10 episodes: 61.6\n",
      "Episode: 156, Rewards: 56.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1284\n",
      "Running average of last 10 episodes: 60.5\n",
      "Episode: 157, Rewards: 18.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1284\n",
      "Running average of last 10 episodes: 56.7\n",
      "Episode: 158, Rewards: 53.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1284\n",
      "Running average of last 10 episodes: 58.7\n",
      "Episode: 159, Rewards: 50.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1284\n",
      "Running average of last 10 episodes: 57.7\n",
      "Episode: 160, Rewards: 55.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1284\n",
      "Running average of last 10 episodes: 57.6\n",
      "Episode: 161, Rewards: 20.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1284\n",
      "Running average of last 10 episodes: 54.8\n",
      "Episode: 162, Rewards: 61.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1284\n",
      "Running average of last 10 episodes: 54.9\n",
      "Episode: 163, Rewards: 65.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1284\n",
      "Running average of last 10 episodes: 55.7\n",
      "Episode: 164, Rewards: 32.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1284\n",
      "Running average of last 10 episodes: 50.9\n",
      "Episode: 165, Rewards: 49.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1284\n",
      "Running average of last 10 episodes: 45.9\n",
      "Episode: 166, Rewards: 12.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1284\n",
      "Running average of last 10 episodes: 41.5\n",
      "Episode: 167, Rewards: 43.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1284\n",
      "Running average of last 10 episodes: 44.0\n",
      "Episode: 168, Rewards: 45.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1284\n",
      "Running average of last 10 episodes: 43.2\n",
      "Episode: 169, Rewards: 38.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1284\n",
      "Running average of last 10 episodes: 42.0\n",
      "Episode: 170, Rewards: 44.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1284\n",
      "Running average of last 10 episodes: 40.9\n",
      "Episode: 171, Rewards: 121.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1284\n",
      "Running average of last 10 episodes: 51.0\n",
      "Episode: 172, Rewards: 46.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1405\n",
      "Running average of last 10 episodes: 49.5\n",
      "Episode: 173, Rewards: 43.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1405\n",
      "Running average of last 10 episodes: 47.3\n",
      "Episode: 174, Rewards: 70.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1405\n",
      "Running average of last 10 episodes: 51.1\n",
      "Episode: 175, Rewards: 30.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1405\n",
      "Running average of last 10 episodes: 49.2\n",
      "Episode: 176, Rewards: 33.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1405\n",
      "Running average of last 10 episodes: 51.3\n",
      "Episode: 177, Rewards: 20.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1405\n",
      "Running average of last 10 episodes: 49.0\n",
      "Episode: 178, Rewards: 39.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1405\n",
      "Running average of last 10 episodes: 48.4\n",
      "Episode: 179, Rewards: 34.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1405\n",
      "Running average of last 10 episodes: 48.0\n",
      "Episode: 180, Rewards: 80.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1405\n",
      "Running average of last 10 episodes: 51.6\n",
      "Episode: 181, Rewards: 61.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1405\n",
      "Running average of last 10 episodes: 45.6\n",
      "Episode: 182, Rewards: 62.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1405\n",
      "Running average of last 10 episodes: 47.2\n",
      "Episode: 183, Rewards: 102.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1405\n",
      "Running average of last 10 episodes: 53.1\n",
      "Episode: 184, Rewards: 82.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1507\n",
      "Running average of last 10 episodes: 54.3\n",
      "Episode: 185, Rewards: 24.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1507\n",
      "Running average of last 10 episodes: 53.7\n",
      "Episode: 186, Rewards: 12.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1507\n",
      "Running average of last 10 episodes: 51.6\n",
      "Episode: 187, Rewards: 90.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1507\n",
      "Running average of last 10 episodes: 58.6\n",
      "Episode: 188, Rewards: 29.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1507\n",
      "Running average of last 10 episodes: 57.6\n",
      "Episode: 189, Rewards: 97.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1507\n",
      "Running average of last 10 episodes: 63.9\n",
      "Episode: 190, Rewards: 47.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1604\n",
      "Running average of last 10 episodes: 60.6\n",
      "Episode: 191, Rewards: 58.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1604\n",
      "Running average of last 10 episodes: 60.3\n",
      "Episode: 192, Rewards: 12.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1604\n",
      "Running average of last 10 episodes: 55.3\n",
      "Episode: 193, Rewards: 122.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1604\n",
      "Running average of last 10 episodes: 57.3\n",
      "Episode: 194, Rewards: 31.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1726\n",
      "Running average of last 10 episodes: 52.2\n",
      "Episode: 195, Rewards: 69.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1726\n",
      "Running average of last 10 episodes: 56.7\n",
      "Episode: 196, Rewards: 86.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1726\n",
      "Running average of last 10 episodes: 64.1\n",
      "Episode: 197, Rewards: 46.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1726\n",
      "Running average of last 10 episodes: 59.7\n",
      "Episode: 198, Rewards: 73.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1726\n",
      "Running average of last 10 episodes: 64.1\n",
      "Episode: 199, Rewards: 74.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1726\n",
      "Running average of last 10 episodes: 61.8\n",
      "Episode: 200, Rewards: 19.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1726\n",
      "Running average of last 10 episodes: 59.0\n",
      "Episode: 201, Rewards: 71.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1726\n",
      "Running average of last 10 episodes: 60.3\n",
      "Episode: 202, Rewards: 73.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1726\n",
      "Running average of last 10 episodes: 66.4\n",
      "Episode: 203, Rewards: 43.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1726\n",
      "Running average of last 10 episodes: 58.5\n",
      "Episode: 204, Rewards: 33.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1726\n",
      "Running average of last 10 episodes: 58.7\n",
      "Episode: 205, Rewards: 41.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1726\n",
      "Running average of last 10 episodes: 55.9\n",
      "Episode: 206, Rewards: 44.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1726\n",
      "Running average of last 10 episodes: 51.7\n",
      "Episode: 207, Rewards: 38.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1726\n",
      "Running average of last 10 episodes: 50.9\n",
      "Episode: 208, Rewards: 107.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1726\n",
      "Running average of last 10 episodes: 54.3\n",
      "Episode: 209, Rewards: 46.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 51.5\n",
      "Episode: 210, Rewards: 50.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 54.6\n",
      "Episode: 211, Rewards: 12.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 48.7\n",
      "Episode: 212, Rewards: 44.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 45.8\n",
      "Episode: 213, Rewards: 15.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 43.0\n",
      "Episode: 214, Rewards: 36.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 43.3\n",
      "Episode: 215, Rewards: 29.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 42.1\n",
      "Episode: 216, Rewards: 51.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 42.8\n",
      "Episode: 217, Rewards: 35.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 42.5\n",
      "Episode: 218, Rewards: 35.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 35.3\n",
      "Episode: 219, Rewards: 44.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 35.1\n",
      "Episode: 220, Rewards: 19.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 32.0\n",
      "Episode: 221, Rewards: 79.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 38.7\n",
      "Episode: 222, Rewards: 53.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 39.6\n",
      "Episode: 223, Rewards: 34.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 41.5\n",
      "Episode: 224, Rewards: 68.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 44.7\n",
      "Episode: 225, Rewards: 76.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 49.4\n",
      "Episode: 226, Rewards: 40.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 48.3\n",
      "Episode: 227, Rewards: 74.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 52.2\n",
      "Episode: 228, Rewards: 38.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 52.5\n",
      "Episode: 229, Rewards: 32.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 51.3\n",
      "Episode: 230, Rewards: 43.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 53.7\n",
      "Episode: 231, Rewards: 101.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1833\n",
      "Running average of last 10 episodes: 55.9\n",
      "Episode: 232, Rewards: 19.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1934\n",
      "Running average of last 10 episodes: 52.5\n",
      "Episode: 233, Rewards: 45.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1934\n",
      "Running average of last 10 episodes: 53.6\n",
      "Episode: 234, Rewards: 99.0\n",
      "Epsilon: \n",
      "0.6\n",
      "Experince amount: \n",
      "1934\n",
      "Running average of last 10 episodes: 56.7\n",
      "Episode: 235, Rewards: 80.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 57.1\n",
      "Episode: 236, Rewards: 46.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 57.7\n",
      "Episode: 237, Rewards: 65.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 56.8\n",
      "Episode: 238, Rewards: 28.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 55.8\n",
      "Episode: 239, Rewards: 28.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 55.4\n",
      "Episode: 240, Rewards: 67.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 57.8\n",
      "Episode: 241, Rewards: 61.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 53.8\n",
      "Episode: 242, Rewards: 10.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 52.9\n",
      "Episode: 243, Rewards: 37.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 52.1\n",
      "Episode: 244, Rewards: 94.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 51.6\n",
      "Episode: 245, Rewards: 46.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 48.2\n",
      "Episode: 246, Rewards: 78.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 51.4\n",
      "Episode: 247, Rewards: 31.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 48.0\n",
      "Episode: 248, Rewards: 46.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 49.8\n",
      "Episode: 249, Rewards: 29.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 49.9\n",
      "Episode: 250, Rewards: 57.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 48.9\n",
      "Episode: 251, Rewards: 57.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 48.5\n",
      "Episode: 252, Rewards: 76.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 55.1\n",
      "Episode: 253, Rewards: 62.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 57.6\n",
      "Episode: 254, Rewards: 52.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 53.4\n",
      "Episode: 255, Rewards: 82.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 57.0\n",
      "Episode: 256, Rewards: 61.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 55.3\n",
      "Episode: 257, Rewards: 154.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2033\n",
      "Running average of last 10 episodes: 67.6\n",
      "Episode: 258, Rewards: 81.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2187\n",
      "Running average of last 10 episodes: 71.1\n",
      "Episode: 259, Rewards: 31.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2187\n",
      "Running average of last 10 episodes: 71.3\n",
      "Episode: 260, Rewards: 96.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2187\n",
      "Running average of last 10 episodes: 75.2\n",
      "Episode: 261, Rewards: 67.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2187\n",
      "Running average of last 10 episodes: 76.2\n",
      "Episode: 262, Rewards: 36.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2187\n",
      "Running average of last 10 episodes: 72.2\n",
      "Episode: 263, Rewards: 88.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2187\n",
      "Running average of last 10 episodes: 74.8\n",
      "Episode: 264, Rewards: 74.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2187\n",
      "Running average of last 10 episodes: 77.0\n",
      "Episode: 265, Rewards: 70.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2187\n",
      "Running average of last 10 episodes: 75.8\n",
      "Episode: 266, Rewards: 140.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2187\n",
      "Running average of last 10 episodes: 83.7\n",
      "Episode: 267, Rewards: 37.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2327\n",
      "Running average of last 10 episodes: 72.0\n",
      "Episode: 268, Rewards: 85.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2327\n",
      "Running average of last 10 episodes: 72.4\n",
      "Episode: 269, Rewards: 128.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2327\n",
      "Running average of last 10 episodes: 82.1\n",
      "Episode: 270, Rewards: 45.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2455\n",
      "Running average of last 10 episodes: 77.0\n",
      "Episode: 271, Rewards: 56.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2455\n",
      "Running average of last 10 episodes: 75.9\n",
      "Episode: 272, Rewards: 65.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2455\n",
      "Running average of last 10 episodes: 78.8\n",
      "Episode: 273, Rewards: 53.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2455\n",
      "Running average of last 10 episodes: 75.3\n",
      "Episode: 274, Rewards: 17.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2455\n",
      "Running average of last 10 episodes: 69.6\n",
      "Episode: 275, Rewards: 142.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2455\n",
      "Running average of last 10 episodes: 76.8\n",
      "Episode: 276, Rewards: 155.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2597\n",
      "Running average of last 10 episodes: 78.3\n",
      "Episode: 277, Rewards: 106.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2752\n",
      "Running average of last 10 episodes: 85.2\n",
      "Episode: 278, Rewards: 37.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2752\n",
      "Running average of last 10 episodes: 80.4\n",
      "Episode: 279, Rewards: 87.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2752\n",
      "Running average of last 10 episodes: 76.3\n",
      "Episode: 280, Rewards: 77.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2752\n",
      "Running average of last 10 episodes: 79.5\n",
      "Episode: 281, Rewards: 173.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2752\n",
      "Running average of last 10 episodes: 91.2\n",
      "Episode: 282, Rewards: 86.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2925\n",
      "Running average of last 10 episodes: 93.3\n",
      "Episode: 283, Rewards: 58.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2925\n",
      "Running average of last 10 episodes: 93.8\n",
      "Episode: 284, Rewards: 124.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2925\n",
      "Running average of last 10 episodes: 104.5\n",
      "Episode: 285, Rewards: 43.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2925\n",
      "Running average of last 10 episodes: 94.6\n",
      "Episode: 286, Rewards: 11.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2925\n",
      "Running average of last 10 episodes: 80.2\n",
      "Episode: 287, Rewards: 53.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2925\n",
      "Running average of last 10 episodes: 74.9\n",
      "Episode: 288, Rewards: 83.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2925\n",
      "Running average of last 10 episodes: 79.5\n",
      "Episode: 289, Rewards: 165.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "2925\n",
      "Running average of last 10 episodes: 87.3\n",
      "Episode: 290, Rewards: 88.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3090\n",
      "Running average of last 10 episodes: 88.4\n",
      "Episode: 291, Rewards: 121.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3090\n",
      "Running average of last 10 episodes: 83.2\n",
      "Episode: 292, Rewards: 68.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3090\n",
      "Running average of last 10 episodes: 81.4\n",
      "Episode: 293, Rewards: 84.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3090\n",
      "Running average of last 10 episodes: 84.0\n",
      "Episode: 294, Rewards: 130.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3090\n",
      "Running average of last 10 episodes: 84.6\n",
      "Episode: 295, Rewards: 72.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3090\n",
      "Running average of last 10 episodes: 87.5\n",
      "Episode: 296, Rewards: 119.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3090\n",
      "Running average of last 10 episodes: 98.3\n",
      "Episode: 297, Rewards: 157.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3090\n",
      "Running average of last 10 episodes: 108.7\n",
      "Episode: 298, Rewards: 33.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3247\n",
      "Running average of last 10 episodes: 103.7\n",
      "Episode: 299, Rewards: 86.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3247\n",
      "Running average of last 10 episodes: 95.8\n",
      "Episode: 300, Rewards: 133.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3247\n",
      "Running average of last 10 episodes: 100.3\n",
      "Episode: 301, Rewards: 120.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3247\n",
      "Running average of last 10 episodes: 100.2\n",
      "Episode: 302, Rewards: 57.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3247\n",
      "Running average of last 10 episodes: 99.1\n",
      "Episode: 303, Rewards: 85.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3247\n",
      "Running average of last 10 episodes: 99.2\n",
      "Episode: 304, Rewards: 19.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3247\n",
      "Running average of last 10 episodes: 88.1\n",
      "Episode: 305, Rewards: 71.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3247\n",
      "Running average of last 10 episodes: 88.0\n",
      "Episode: 306, Rewards: 95.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3247\n",
      "Running average of last 10 episodes: 85.6\n",
      "Episode: 307, Rewards: 108.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3247\n",
      "Running average of last 10 episodes: 80.7\n",
      "Episode: 308, Rewards: 115.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3247\n",
      "Running average of last 10 episodes: 88.9\n",
      "Episode: 309, Rewards: 106.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3247\n",
      "Running average of last 10 episodes: 90.9\n",
      "Episode: 310, Rewards: 36.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3247\n",
      "Running average of last 10 episodes: 81.2\n",
      "Episode: 311, Rewards: 175.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3247\n",
      "Running average of last 10 episodes: 86.7\n",
      "Episode: 312, Rewards: 88.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3422\n",
      "Running average of last 10 episodes: 89.8\n",
      "Episode: 313, Rewards: 96.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3422\n",
      "Running average of last 10 episodes: 90.9\n",
      "Episode: 314, Rewards: 65.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3422\n",
      "Running average of last 10 episodes: 95.5\n",
      "Episode: 315, Rewards: 22.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3422\n",
      "Running average of last 10 episodes: 90.6\n",
      "Episode: 316, Rewards: 83.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3422\n",
      "Running average of last 10 episodes: 89.4\n",
      "Episode: 317, Rewards: 113.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3422\n",
      "Running average of last 10 episodes: 89.9\n",
      "Episode: 318, Rewards: 66.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3422\n",
      "Running average of last 10 episodes: 85.0\n",
      "Episode: 319, Rewards: 175.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3422\n",
      "Running average of last 10 episodes: 91.9\n",
      "Episode: 320, Rewards: 49.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3597\n",
      "Running average of last 10 episodes: 93.2\n",
      "Episode: 321, Rewards: 57.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3597\n",
      "Running average of last 10 episodes: 81.4\n",
      "Episode: 322, Rewards: 104.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3597\n",
      "Running average of last 10 episodes: 83.0\n",
      "Episode: 323, Rewards: 84.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3597\n",
      "Running average of last 10 episodes: 81.8\n",
      "Episode: 324, Rewards: 81.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3597\n",
      "Running average of last 10 episodes: 83.4\n",
      "Episode: 325, Rewards: 94.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3597\n",
      "Running average of last 10 episodes: 90.6\n",
      "Episode: 326, Rewards: 100.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3597\n",
      "Running average of last 10 episodes: 92.3\n",
      "Episode: 327, Rewards: 20.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3597\n",
      "Running average of last 10 episodes: 83.0\n",
      "Episode: 328, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3597\n",
      "Running average of last 10 episodes: 96.4\n",
      "Episode: 329, Rewards: 106.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3797\n",
      "Running average of last 10 episodes: 89.5\n",
      "Episode: 330, Rewards: 59.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3797\n",
      "Running average of last 10 episodes: 90.5\n",
      "Episode: 331, Rewards: 68.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3797\n",
      "Running average of last 10 episodes: 91.6\n",
      "Episode: 332, Rewards: 43.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3797\n",
      "Running average of last 10 episodes: 85.5\n",
      "Episode: 333, Rewards: 82.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3797\n",
      "Running average of last 10 episodes: 85.3\n",
      "Episode: 334, Rewards: 87.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3797\n",
      "Running average of last 10 episodes: 85.9\n",
      "Episode: 335, Rewards: 60.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3797\n",
      "Running average of last 10 episodes: 82.5\n",
      "Episode: 336, Rewards: 109.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3797\n",
      "Running average of last 10 episodes: 83.4\n",
      "Episode: 337, Rewards: 24.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3797\n",
      "Running average of last 10 episodes: 83.8\n",
      "Episode: 338, Rewards: 147.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3797\n",
      "Running average of last 10 episodes: 78.5\n",
      "Episode: 339, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3797\n",
      "Running average of last 10 episodes: 87.9\n",
      "Episode: 340, Rewards: 89.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3997\n",
      "Running average of last 10 episodes: 90.9\n",
      "Episode: 341, Rewards: 19.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3997\n",
      "Running average of last 10 episodes: 86.0\n",
      "Episode: 342, Rewards: 122.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3997\n",
      "Running average of last 10 episodes: 93.9\n",
      "Episode: 343, Rewards: 82.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3997\n",
      "Running average of last 10 episodes: 93.9\n",
      "Episode: 344, Rewards: 182.0\n",
      "Epsilon: \n",
      "0.5\n",
      "Experince amount: \n",
      "3997\n",
      "Running average of last 10 episodes: 103.4\n",
      "Episode: 345, Rewards: 122.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4179\n",
      "Running average of last 10 episodes: 109.6\n",
      "Episode: 346, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4179\n",
      "Running average of last 10 episodes: 118.7\n",
      "Episode: 347, Rewards: 136.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4379\n",
      "Running average of last 10 episodes: 129.9\n",
      "Episode: 348, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4379\n",
      "Running average of last 10 episodes: 135.2\n",
      "Episode: 349, Rewards: 94.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4579\n",
      "Running average of last 10 episodes: 124.6\n",
      "Episode: 350, Rewards: 104.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4579\n",
      "Running average of last 10 episodes: 126.1\n",
      "Episode: 351, Rewards: 126.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4579\n",
      "Running average of last 10 episodes: 136.8\n",
      "Episode: 352, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4579\n",
      "Running average of last 10 episodes: 144.6\n",
      "Episode: 353, Rewards: 79.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4779\n",
      "Running average of last 10 episodes: 144.3\n",
      "Episode: 354, Rewards: 139.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4779\n",
      "Running average of last 10 episodes: 140.0\n",
      "Episode: 355, Rewards: 36.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4779\n",
      "Running average of last 10 episodes: 131.4\n",
      "Episode: 356, Rewards: 73.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4779\n",
      "Running average of last 10 episodes: 118.7\n",
      "Episode: 357, Rewards: 129.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4779\n",
      "Running average of last 10 episodes: 118.0\n",
      "Episode: 358, Rewards: 129.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4779\n",
      "Running average of last 10 episodes: 110.9\n",
      "Episode: 359, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4779\n",
      "Running average of last 10 episodes: 121.5\n",
      "Episode: 360, Rewards: 160.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4979\n",
      "Running average of last 10 episodes: 127.1\n",
      "Episode: 361, Rewards: 43.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4979\n",
      "Running average of last 10 episodes: 118.8\n",
      "Episode: 362, Rewards: 41.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4979\n",
      "Running average of last 10 episodes: 102.9\n",
      "Episode: 363, Rewards: 153.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4979\n",
      "Running average of last 10 episodes: 110.3\n",
      "Episode: 364, Rewards: 104.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4979\n",
      "Running average of last 10 episodes: 106.8\n",
      "Episode: 365, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.4\n",
      "Experince amount: \n",
      "4979\n",
      "Running average of last 10 episodes: 123.2\n",
      "Episode: 366, Rewards: 178.0\n",
      "Epsilon: \n",
      "0.3\n",
      "Experince amount: \n",
      "5179\n",
      "Running average of last 10 episodes: 133.7\n",
      "Episode: 367, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.3\n",
      "Experince amount: \n",
      "5357\n",
      "Running average of last 10 episodes: 140.8\n",
      "Episode: 368, Rewards: 152.0\n",
      "Epsilon: \n",
      "0.3\n",
      "Experince amount: \n",
      "5557\n",
      "Running average of last 10 episodes: 143.1\n",
      "Episode: 369, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.3\n",
      "Experince amount: \n",
      "5557\n",
      "Running average of last 10 episodes: 143.1\n",
      "Episode: 370, Rewards: 158.0\n",
      "Epsilon: \n",
      "0.3\n",
      "Experince amount: \n",
      "5757\n",
      "Running average of last 10 episodes: 142.9\n",
      "Episode: 371, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.3\n",
      "Experince amount: \n",
      "5757\n",
      "Running average of last 10 episodes: 158.6\n",
      "Episode: 372, Rewards: 105.0\n",
      "Epsilon: \n",
      "0.3\n",
      "Experince amount: \n",
      "5957\n",
      "Running average of last 10 episodes: 165.0\n",
      "Episode: 373, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.3\n",
      "Experince amount: \n",
      "5957\n",
      "Running average of last 10 episodes: 169.7\n",
      "Episode: 374, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.2\n",
      "Experince amount: \n",
      "6157\n",
      "Running average of last 10 episodes: 179.3\n",
      "Episode: 375, Rewards: 195.0\n",
      "Epsilon: \n",
      "0.2\n",
      "Experince amount: \n",
      "6357\n",
      "Running average of last 10 episodes: 178.8\n",
      "Episode: 376, Rewards: 161.0\n",
      "Epsilon: \n",
      "0.2\n",
      "Experince amount: \n",
      "6552\n",
      "Running average of last 10 episodes: 177.1\n",
      "Episode: 377, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.2\n",
      "Experince amount: \n",
      "6713\n",
      "Running average of last 10 episodes: 177.1\n",
      "Episode: 378, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.2\n",
      "Experince amount: \n",
      "6913\n",
      "Running average of last 10 episodes: 181.9\n",
      "Episode: 379, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.1\n",
      "Experince amount: \n",
      "7113\n",
      "Running average of last 10 episodes: 181.9\n",
      "Episode: 380, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.1\n",
      "Experince amount: \n",
      "7313\n",
      "Running average of last 10 episodes: 186.1\n",
      "Episode: 381, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.1\n",
      "Experince amount: \n",
      "7513\n",
      "Running average of last 10 episodes: 186.1\n",
      "Episode: 382, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.1\n",
      "Experince amount: \n",
      "7713\n",
      "Running average of last 10 episodes: 195.6\n",
      "Episode: 383, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.1\n",
      "Experince amount: \n",
      "7913\n",
      "Running average of last 10 episodes: 195.6\n",
      "Episode: 384, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.1\n",
      "Experince amount: \n",
      "8113\n",
      "Running average of last 10 episodes: 195.6\n",
      "Episode: 385, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.1\n",
      "Experince amount: \n",
      "8313\n",
      "Running average of last 10 episodes: 196.1\n",
      "Episode: 386, Rewards: 200.0\n",
      "Epsilon: \n",
      "0.1\n",
      "Experince amount: \n",
      "8513\n",
      "Running average of last 10 episodes: 200.0\n",
      "Solved!\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-abd278009bd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mfile_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Solved!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "wondering_gnome = PolyGradAgent(env.action_space)\n",
    "\n",
    "for i_episode in range(10000):\n",
    "\n",
    "    observation = env.reset()\n",
    "    episode_rewards = 0      \n",
    "    episode_states_list = []\n",
    "    episode_actions_list = []\n",
    "    \n",
    "    \n",
    "        \n",
    "    for t in range(200):\n",
    "        # env.render()\n",
    "        #print observation\n",
    "\n",
    "        state_for_mem = observation\n",
    "        \n",
    "        current_state =  np.expand_dims(observation, axis=0)\n",
    "        \n",
    "        current_state = current_state.reshape(1,1,4)\n",
    "\n",
    "        action = env.action_space.sample()  # initialize action randomly\n",
    "        \n",
    "        if wondering_gnome.network_has_had_training:\n",
    "\n",
    "            random_fate = np.random.random()\n",
    "                      \n",
    "            raw_output = logits.eval(feed_dict = {state: current_state}) # , keep_prob: 1.0})\n",
    "\n",
    "            if random_fate > wondering_gnome.epsilon:  # e-greedy implementation\n",
    "            \n",
    "                action = np.argmax(raw_output)\n",
    "        \n",
    "        \n",
    "        episode_states_list.append(observation) # append this state to our episode states list\n",
    "        episode_actions_list.append(action) # append chosen action to our episode actions list\n",
    "\n",
    "        ## Action step\n",
    "        observation, reward, done, info = env.step(action)\n",
    "       \n",
    "        ## Add this state's reward to our episode rewards\n",
    "        episode_rewards += reward\n",
    "        \n",
    "        ## If we're done exit the episode loop\n",
    "        if done:           \n",
    "            break\n",
    "\n",
    "    ## Print some episode summary info\n",
    "    print(\"Episode: \" + str(i_episode) + \", \" + \"Rewards: \" + str(episode_rewards))\n",
    "    print(\"Epsilon: \")\n",
    "    print(wondering_gnome.epsilon)\n",
    "    print(\"Experince amount: \")\n",
    "    print(wondering_gnome.experience)\n",
    "   \n",
    "    # Add episode score to last 10 scores\n",
    "    wondering_gnome.last_10_episode_scores.append(episode_rewards)\n",
    "    print(\"Running average of last 10 episodes: \" + str(np.average(wondering_gnome.last_10_episode_scores)))\n",
    "\n",
    "    ## If we've solved the environment close our log writer and exit\n",
    "    if np.average(wondering_gnome.last_10_episode_scores) >= 199.0:\n",
    "\n",
    "        file_writer.close()\n",
    "        print(\"Solved!\")\n",
    "        assert False\n",
    "\n",
    "  \n",
    "    wondering_gnome.update_high_score(episode_rewards)  # update high score\n",
    "\n",
    "\n",
    "\n",
    "    pre_np_states = np.array(episode_states_list)\n",
    "    np_states = pre_np_states.reshape(pre_np_states.shape[0], 1, pre_np_states.shape[1]) # Our LSTM needs a tensor of order 3 for training\n",
    "\n",
    "    np_actions = np.array(episode_actions_list)\n",
    "\n",
    "    batch = (np_states, np_actions)\n",
    "\n",
    "    ## If we did well update our last good batch and amount of experience\n",
    "    if wondering_gnome.did_we_do_well(episode_rewards):\n",
    "\n",
    "        wondering_gnome.last_good_batch = batch\n",
    "\n",
    "        wondering_gnome.experience += len(episode_states_list)\n",
    "\n",
    "        # Decay our epsilon using one of our two strategies \n",
    "        #wondering_gnome.decay_epsilon()\n",
    "        wondering_gnome.decay_epsilon_custom()\n",
    "    \n",
    "    ## Train our LSTM after every episode, but only with our most recent good batch\n",
    "    train_step.run(feed_dict={state: wondering_gnome.last_good_batch[0], actions: wondering_gnome.last_good_batch[1]}) # , keep_prob: 0.75})\n",
    "\n",
    "    ## LSTM has been trained\n",
    "    if i_episode > 1:\n",
    "        wondering_gnome.network_has_had_training = True\n",
    "\n",
    "    ##  Current loss logging\n",
    "    if i_episode % 20 == 0:\n",
    "        summary_str = loss_summary.eval(feed_dict={state: wondering_gnome.last_good_batch[0], actions: wondering_gnome.last_good_batch[1]})\n",
    "        step = i_episode\n",
    "        file_writer.add_summary(summary_str, step)\n",
    "env.close()\n",
    "show_video() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBh2VKS0mJpq",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XI1uy9Z7j7NZ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Hami.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
